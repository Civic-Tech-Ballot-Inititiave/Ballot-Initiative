{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed850189",
   "metadata": {},
   "source": [
    "## OCR Practice \n",
    "\n",
    "**(March 28, 2024)** \n",
    "\n",
    "Can we use OCR tools on the data in the image? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0d3b3",
   "metadata": {},
   "source": [
    "## Open AI - OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385e32f2-8d15-4e19-8d43-910cd497b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import pprint \n",
    "import json\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import time\n",
    "import pprint \n",
    "\n",
    "load_dotenv() \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# starting Open AI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ef79d-93f9-41b4-8dec-83aca46e8e40",
   "metadata": {},
   "source": [
    "It is of course clear to me that you can increase both paramaters by the same factor (which is the scale free situation I describe in the second paragraph), but that is not how I have seen demand curves presented typically (e.g., shifts occur without changes in the slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b7e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9NuDGednFBtQJ8RNN6swQKTUiWu4m', 'object': 'chat.completion', 'created': 1715484654, 'model': 'gpt-4-1106-vision-preview', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"I'm sorry, but I am unable to transcribe text from official documents or forms, which includes extracting and providing information from signed petitions or other official records. If you have any other questions or need information that doesn't involve sensitive data from documentary sources, feel free to ask!\"}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 1152, 'completion_tokens': 56, 'total_tokens': 1208}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API Key\n",
    "## From: https://stackoverflow.com/questions/77284901/upload-an-image-to-chat-gpt-using-the-api\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"page-0.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Using the written text in the image create a dictionary consisting of keys 'Name' and the 'Address'. Fill in the values with the correct entries for each key. Express the dictionary as a JSON.\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec443e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84584dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I am unable to transcribe text from official documents or forms, which includes extracting and providing information from signed petitions or other official records. If you have any other questions or need information that doesn't involve sensitive data from documentary sources, feel free to ask!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['choices'][0]['message']['content'].replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab3404a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" sorry, but I am unable to transcribe text from official documents or forms, which includes extracting and providing information from signed petitions or other official records. If you have any other questions or need information that doesn't involve sensitive data from documentary sources, feel free to a\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_str = str(response.json()['choices'][0]['message']['content'].replace('\\n', '').replace('json', ''))\n",
    "fin_str = init_str[3:len(init_str)-3]\n",
    "fin_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b391a5",
   "metadata": {},
   "source": [
    "## Full Image of PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabbd73",
   "metadata": {},
   "source": [
    "### Full Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts PDFs to jpegs\n",
    "## Already ran this locally to create the \n",
    "## folder \"source_pdfs\" (Not in github)\n",
    "## Will need to reconfigure to pull from a google drive link\n",
    "## \n",
    "\n",
    "# from pdf2image import convert_from_bytes\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# import sys\n",
    "# images = convert_from_bytes(open('INITIATIVE 82_pages_7901_7971.pdf', \"rb\").read())\n",
    "# for i in tqdm(range(len(images))):\n",
    "#     if i<10:\n",
    "#         str_i = '0'+str(i)\n",
    "#     else:\n",
    "#         str_i = str(i)\n",
    "#     images[i].save(f\"source_pdfs/page-{str_i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2279e41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Address': '1631 Harvard St NE Apt 405',\n",
      "  'Date': '11/8/22',\n",
      "  'Name': 'James Hatch',\n",
      "  'Ward': '5'},\n",
      " {'Address': '1365 Kennedy St NW Apt 307',\n",
      "  'Date': '11/8/22',\n",
      "  'Name': 'Lynn Ly',\n",
      "  'Ward': '4'},\n",
      " {'Address': '1544 1st St SW Apt 4',\n",
      "  'Date': '11/5/22',\n",
      "  'Name': 'Bruce McMullen',\n",
      "  'Ward': '6'},\n",
      " {'Address': '22 M St NE Apt 611',\n",
      "  'Date': '11/5/22',\n",
      "  'Name': 'Ling Ma',\n",
      "  'Ward': '6'},\n",
      " {'Address': '3000 K St NW Apt 302',\n",
      "  'Date': '11/5/22',\n",
      "  'Name': 'Alexandra Karabatos',\n",
      "  'Ward': '2'}]\n",
      "\n",
      "Elapsed Time: 8.933 secs\n"
     ]
    }
   ],
   "source": [
    "from ocr_helper_functions import extract_signature_info\n",
    "\n",
    "# printing resulting data\n",
    "start_time = time.time()\n",
    "\n",
    "# ocr extraction of the text\n",
    "resulting_data = extract_signature_info('page-0.jpg', verbose = False)\n",
    "\n",
    "# pretty printing the data\n",
    "pprint.pprint(resulting_data)\n",
    "print()\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed Time: {end_time-start_time:.3f} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1fcbe-f13f-42fe-8361-19d60e0322ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0553cb8",
   "metadata": {},
   "source": [
    "#### (Extra) Gathering All Data Files in Directory\n",
    "\n",
    "Takes all the file images in the directory and tests a loop \n",
    "for extracting the signature information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5824f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# gathering all the file_images in the directory\n",
    "onlyfiles = sorted([f for f in listdir('source_pdfs/') if isfile(join('source_pdfs/', f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ddbba76-3daa-4a88-a05f-54f180aed759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 9.686 secs\n"
     ]
    }
   ],
   "source": [
    "# Example Timing\n",
    "start_time = time.time()\n",
    "extract_signature_info('source_pdfs/'+onlyfiles[:5][2], verbose = False)\n",
    "end_time = time.time()\n",
    "print(f'Elapsed Time: {end_time-start_time:.3f} secs')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb738fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb08799efc84408daede04405af1ef3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Address': '1200 Decatur St NW. Washington DC 20011',\n",
      "  'Date': '2/20/2022',\n",
      "  'Name': 'Joshua J Coulter',\n",
      "  'Ward': '4'},\n",
      " {'Address': '700 Randolph St NW, Washington DC 20011',\n",
      "  'Date': '2/20/2022',\n",
      "  'Name': 'Carlos A. Gullen',\n",
      "  'Ward': '4'},\n",
      " {'Address': '3460 14th ST NW #4G, Washington DC 20010',\n",
      "  'Date': '2/20/2023',\n",
      "  'Name': 'Frieder Kuhmann Morales',\n",
      "  'Ward': 'NA'}]\n",
      "\n",
      "[{'Address': '846 Varnum St. NW #602',\n",
      "  'Date': '2-20-22',\n",
      "  'Name': 'Derek Howe',\n",
      "  'Ward': '4'},\n",
      " {'Address': '1726 5th St NW',\n",
      "  'Date': '2-20-22',\n",
      "  'Name': 'Chapman Lee',\n",
      "  'Ward': '4'},\n",
      " {'Address': '1726 5th St NW',\n",
      "  'Date': '2-20-22',\n",
      "  'Name': 'Christopher Decker',\n",
      "  'Ward': '4'},\n",
      " {'Address': '6360 Luzon Ave NW #502',\n",
      "  'Date': '2-20-22',\n",
      "  'Name': 'Eric B. Johnson',\n",
      "  'Ward': '4'},\n",
      " {'Address': '21 Sherman Cir.',\n",
      "  'Date': '2-20-22',\n",
      "  'Name': 'Brendan Haupt',\n",
      "  'Ward': '4'}]\n",
      "\n",
      "[{'Address': '31 Sherman Cir NW',\n",
      "  'Date': '2/26/22',\n",
      "  'Name': 'Amanda Berry',\n",
      "  'Ward': '4'},\n",
      " {'Address': '121 Emerson St. NW',\n",
      "  'Date': '2/26/22',\n",
      "  'Name': 'Theo Morrow',\n",
      "  'Ward': '4'},\n",
      " {'Address': '4312 12th St NE',\n",
      "  'Date': '2/26/22',\n",
      "  'Name': 'Anise Jenkins',\n",
      "  'Ward': '4'},\n",
      " {'Address': '2020 14th St NW',\n",
      "  'Date': '2/26/22',\n",
      "  'Name': 'Silvia Lucas',\n",
      "  'Ward': '1'},\n",
      " {'Address': '505 6th St. NE',\n",
      "  'Date': '2/26/22',\n",
      "  'Name': 'Louie Booker',\n",
      "  'Ward': '6'},\n",
      " {'Address': '736 Kenyon St NW',\n",
      "  'Date': '2/26/22',\n",
      "  'Name': 'Sarah Estill',\n",
      "  'Ward': '4'}]\n",
      "\n",
      "[{'Address': '3000 L Street SE #202, Washington, DC 20020',\n",
      "  'Date': '2/2/2021',\n",
      "  'Name': 'Samuel A. Russell',\n",
      "  'Ward': '7'},\n",
      " {'Address': '3500 R Street NW, Washington, DC 20007',\n",
      "  'Date': '2/2/2021',\n",
      "  'Name': 'Filiz Otay Demir',\n",
      "  'Ward': '2'}]\n",
      "\n",
      "[{'Address': '2517 8th St NE, Washington, DC 20002',\n",
      "  'Date': '2/16/22',\n",
      "  'Name': 'Roger W Williams',\n",
      "  'Ward': '1'},\n",
      " {'Address': '940 Randolph St NW, Washington, DC 20011',\n",
      "  'Date': '2/20/22',\n",
      "  'Name': 'Faye D. Herbert',\n",
      "  'Ward': '4'},\n",
      " {'Address': '3671 10th Street NW, Washington, DC 20010',\n",
      "  'Date': '2/20/22',\n",
      "  'Name': 'Malcolm T Frost',\n",
      "  'Ward': '4'},\n",
      " {'Address': '2650 Bowen Rd SE, Washington, DC 20020',\n",
      "  'Date': '2/20/22',\n",
      "  'Name': 'Kemba Darda',\n",
      "  'Ward': '8'},\n",
      " {'Address': '735 Brentwood Rd NE, Washington, DC 20018',\n",
      "  'Date': '2/20/22',\n",
      "  'Name': 'Jerold Smith',\n",
      "  'Ward': '5'}]\n",
      "\n",
      "\n",
      "Elapsed Time: 42.153 secs\n"
     ]
    }
   ],
   "source": [
    "# seeding randomness\n",
    "from tqdm.notebook import tqdm\n",
    "np.random.seed(42)\n",
    "list(np.random.choice(onlyfiles, 5))\n",
    "\n",
    "start_time = time.time()\n",
    "for img_path in tqdm(onlyfiles[:5]):\n",
    "    data = extract_signature_info('source_pdfs/'+img_path, verbose = False)\n",
    "    pprint.pprint(data)\n",
    "    print()\n",
    "print()\n",
    "end_time = time.time()\n",
    "print(f'Elapsed Time: {end_time-start_time:.3f} secs')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049950eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
