{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde1562e",
   "metadata": {},
   "source": [
    "\n",
    "## What you need to be able to run this notebook (and the application)\n",
    "\n",
    "- **Open AI API key:** Key allows you to query various GPT models, in particular the image model that we use to perform the optical character recognition\n",
    "    - Go here to sign up for Open AI account and get an API key https://platform.openai.com/docs/quickstart\n",
    "    - When you get your API key, create a file called `.env` in the home directory of this repository (i.e., not within the directory of this notebook but the one that contains the notebook directory) and add the line `OPENAI_API_KEY = <YOUR API KEY>` anywhere inside. \n",
    "- **Python Libraries:** Uncomment and execute the cell below to install all the requirements needed for the application and notebook. NOTE: You would probably want to be in a virtual environment to avoid adding these libraries to your global Python libraries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba16851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## installing requirements; uncomment line below\n",
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80002150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed libraries\n",
    "import base64\n",
    "import pprint\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from rapidfuzz import fuzz, process, utils\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c02ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading environmental variables\n",
    "load_dotenv('../.env', override=True)\n",
    "\n",
    "# define your open AI API key here; Remember this is a personal notebook! Don't push your API key to the remote repo\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99716df",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4627f",
   "metadata": {},
   "source": [
    "# Onboarding Noteboook\n",
    "\n",
    "**(July 18, 2024)** \n",
    "\n",
    "Woot! Thanks for your interest in the Ballot Initiative Project! This notebook was created to walk you through the main parts of the project (as they exist according to the above date), and thus give you a good background on how to contribute to the fundamental tech stack. Currently the application is quite simple, but we are working each month to improve functionality and usability and YOU can be a part of these improvements! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde674f",
   "metadata": {},
   "source": [
    "## The Ballot Initiative Problem\n",
    "\n",
    "Let' say you wanted to get a minimum wage increase on the ballot in DC. By get \"on the ballot,\" we mean put the \"Should Minimum Wage be raised to $15?\" question on a ballot in the next election. That way voters could vote on the issue and it could be changed city wide.\n",
    "\n",
    "How would you get such an issue on the ballot? According to the the City Council of DC (https://code.dccouncil.gov/us/dc/council/code/sections/1-1001.16), after getting your initiative approved by the council, you would then need to collect signatures from the registered voters in the district. If you get enough *validated* signatures, then your issue gets on the ballot and people can vote on it. But How many validated signatures do you need?  Here is a direct quote from the website:\n",
    "\n",
    "> In order for any initiative measure or referendum measure to qualify for the ballot for consideration by the electors of the District, the proposer of the initiative measure or referendum measure shall secure the valid signatures of registered qualified electors upon the initiative or referendum measure equal in number to **5% of the registered qualified electors in the District; provided, that the total signatures submitted include 5% of the registered qualified electors in each of 5 or more of the 8 wards**.\n",
    "\n",
    "So you would need to get 5% of the total population of registered voters and 5% per ward (for at least 5 wards) for registered voters. How could you ensure you meet this threshold? Mostly through ballpark estimates. You get a bunch of volunteers to go out into the city and collect signatures, and then at the end of the day you tally how many you collected. You keep a running tally per ward, and you check the results against a voter database, so that when you finally submit the list to the DC BOE you have a good sense of how many signatures are valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06be9872",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7e871",
   "metadata": {},
   "source": [
    "![alt text](ballot_initiative_flow.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f6faff",
   "metadata": {},
   "source": [
    "The general data flow of the project is shown above. PDFs of ballots come in and a validated list of those who signed the ballot comes out. This flow can be broken into two parts an OCR (i.e., Optical Character Recognition) part and a Validation/Match part. Here are \n",
    "\n",
    "**OCR Processing of Signatures**\n",
    "- A collection of signed ballots in PDF format come in. We select a single page of that PDF. We convert that page into an image (importantly one that can be ingested by GPT). We use GPT's vision capabilities to perform Optical Character Recognition on the image, and extract the names and addresses of those who signed the ballot. \n",
    "\n",
    "**Validation/Matching of Extracted Signatures**\n",
    "- From the collection of names and addresses, we compare the elements of the list with a record of voters. We want to determine whether the voter name and address extracted from the ballot matches one found in the Voter Record. If there is a match, then that voter record is said to be validated. \n",
    "\n",
    "Below we breakdown what pieces of this process currently exist and we end by outlining some ways to contribute to the existing project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081fa43",
   "metadata": {},
   "source": [
    "## OCR Processing of Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ca98a",
   "metadata": {},
   "source": [
    "#### Basic GPT Image Recognition\n",
    "\n",
    "For our OCR, we are using the Open AI Vision API (described here: https://platform.openai.com/docs/guides/vision) to extract signatures from a PDF page of the ballot. To get familiar with using it we can consider a simpler example than a ballot and ask GPT to explain the Ballot Initiative diagram at the start of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947acda4",
   "metadata": {},
   "source": [
    "The first thing we need to do is put the image in a format that the API can recognize. Below is a function (complete with the stackoverflow page it was stolen from) that properly converts the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdacb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is needed to put image in proper format for uploading\n",
    "# From: https://stackoverflow.com/questions/77284901/upload-an-image-to-chat-gpt-using-the-api\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779c155",
   "metadata": {},
   "source": [
    "Next, we apply the function to the `ballo_inititiave_flow.png` file that exists at the start of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15e939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "image_path = \"ballot_initiative_flow.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60f3f0",
   "metadata": {},
   "source": [
    "Finally we ask the API to explain the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ed90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diagram outlines the workflow for processing signed forms related to a ballot initiative project. Hereâ€™s a breakdown of the steps involved:\n",
      "\n",
      "1. **Signed Forms in PDF Format**: The process begins with a collection of signed forms stored in PDF format.\n",
      "\n",
      "2. **Select Single Form**: A specific form is selected from the collection for further processing.\n",
      "\n",
      "3. **Convert to Image**: The selected PDF form is converted into an image format to facilitate text extraction.\n",
      "\n",
      "4. **Open AI API**: The image is then processed using the OpenAI API, specifically utilizing the GPT-4 vision API along with OCR (Optical Character Recognition) prompt engineering to extract text.\n",
      "\n",
      "5. **Extracted Text**: The extracted text includes key information such as names, addresses, wards, and dates, formatted as a list of dictionaries.\n",
      "\n",
      "6. **Python Package: rapidfuzz**: The extracted data is then processed using the Python package \"rapidfuzz\" for fuzzy matching, which helps in validating the extracted information against existing records.\n",
      "\n",
      "7. **Database of Voting Records**: The validated data is compared to a database (or dataframe) of voting records to ensure accuracy.\n",
      "\n",
      "8. **Output Table**: Finally, the results are compiled into a table that lists names, addresses, validation scores, and their validation status (e.g., whether the information is valid).\n",
      "\n",
      "Overall, the diagram illustrates a systematic approach to digitizing and validating signed forms for a ballot initiative, leveraging AI and data processing techniques.\n"
     ]
    }
   ],
   "source": [
    "# sample use of open AI API\n",
    "\n",
    "prompt = \"Please explain the meaning of the provided diagram.\"\n",
    "\n",
    "client = OpenAI(api_key= OPENAI_API_KEY)\n",
    "\n",
    "messages = [{\"role\": \"user\",\n",
    "             \"content\": [{\"type\": \"text\",\n",
    "                          \"text\": prompt},\n",
    "                          {\"type\": \"image_url\",\n",
    "                           \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                           }\n",
    "                        ]\n",
    "              }\n",
    "              ]\n",
    "\n",
    "results = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(results.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74956121",
   "metadata": {},
   "source": [
    "#### Extract Signature Function\n",
    "\n",
    "Following the simple example above, we can now pursue the desired use case: Extracting signatures from a jpg version of a ballot. We currently have a prompt to do this, but we have to tell the API that these signatures are \"toy examples,\" in order for it to properly process the personal data. So this is not an ideal approach to OCR. Finding better OCR approaches is one of the tasks that can be worked on for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596ada50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signature_info(image_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts names and addresses from single ballot image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    # open AI client definition\n",
    "    client = OpenAI(api_key= OPENAI_API_KEY)\n",
    "\n",
    "    # prompt message\n",
    "    messages = [\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"\"\"Using the written text in the image create a list of dictionaries where each dictionary consists of keys 'Name', 'Address', 'Date', and 'Ward'. Fill in the values of each dictionary with the correct entries for each key. Write all the values of the dictionary in full. Only output the list of dictionaries. No other intro text is necessary. The output should be in JSON format, and look like\n",
    "                {'data': [{\"Name\": \"John Doe\",\n",
    "                          \"Address\": \"123 Picket Lane\",\n",
    "                          \"Date\": \"11/23/2024\",\n",
    "                          \"Ward\": \"2\"},\n",
    "                          {\"Name\": \"Jane Plane\",\n",
    "                          \"Address\": \"456 Fence Field\",\n",
    "                          \"Date\": \"11/23/2024\",\n",
    "                          \"Ward\": \"3\"},\n",
    "                          ]} \"\"\"\n",
    "              },\n",
    "              {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                  \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "\n",
    "    # processing result through GPT\n",
    "    results = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    # convert json into list\n",
    "    signator_list = json.loads(results.choices[0].message.content)['data']\n",
    "\n",
    "    return signator_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04965c8",
   "metadata": {},
   "source": [
    "Testing function on single ballot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b9a1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Address': '1234 Main St, Seattle, WA 98101',\n",
      "  'Date': '11/15/2022',\n",
      "  'Name': 'Marion Jones',\n",
      "  'Ward': '1'},\n",
      " {'Address': '980 Oak Dr, Seattle, WA 98103',\n",
      "  'Date': '1/15/2022',\n",
      "  'Name': 'James Smith',\n",
      "  'Ward': '2'},\n",
      " {'Address': '765 Cedar Ln, Seattle, WA 98105',\n",
      "  'Date': '1/15/2022',\n",
      "  'Name': 'Sarah Williams',\n",
      "  'Ward': '3'},\n",
      " {'Address': '432 Elm St, Seattle, WA 98104',\n",
      "  'Date': '1/15/2022',\n",
      "  'Name': 'Michael Johnson',\n",
      "  'Ward': '4'},\n",
      " {'Address': '765 Cedar Ln, Seattle, WA 98105',\n",
      "  'Date': '1/15/2022',\n",
      "  'Name': 'Emily Brown',\n",
      "  'Ward': '5'}]\n",
      "\n",
      "Elapsed Time: 8.775 secs\n"
     ]
    }
   ],
   "source": [
    "# timing the result\n",
    "start_time = time.time()\n",
    "\n",
    "# get home github directory\n",
    "repo_root = os.path.dirname(os.path.dirname(os.path.abspath('notebooks')))\n",
    "\n",
    "# ocr extraction of the text\n",
    "resulting_data = extract_signature_info(f'{repo_root}/sample_data/page-0.jpg')\n",
    "\n",
    "# pretty printing the data; ; uncomment in the notebook run\n",
    "pprint.pprint(resulting_data)\n",
    "\n",
    "# recording elapsed time; uncomment in the notebook run\n",
    "print(f'\\nElapsed Time: {time.time()-start_time:.3f} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3ce9a",
   "metadata": {},
   "source": [
    "## Validation/Matching of Extracted Signatures\n",
    "\n",
    "The second part of the pipeline is the validation/matching of the extracted signatures through \"fuzzy matching\" (https://en.wikipedia.org/wiki/Approximate_string_matching) between the OCR output of the ballot pages and a voter records file. Why is this necessary? Here is a direct quote from the council of DC page. \n",
    "\n",
    "> For the purpose of verifying a signature on any petition filed pursuant to this section, **the Board shall first determine that the address on the petition is the same as the residence shown on the signerâ€™s voter registration record. If the address is different, the signature shall not be counted as valid unless the Boardâ€™s records show that the person was registered to vote from the address listed on the petition at the time the person signed the petition.**\n",
    "\n",
    "So for each signature in an initiative, we need to extract the name of the signor and their address and we need to ensure that both exist in the record of registered voters. The OCR output is not always a clean name and address (i.e., it's not always the exact name/address the signor intended to write), so we need to find a way to collect the \"closest matches\" to the names and addresses in the voter records file. The next few cells walk through how we do this for names only. We will also need to do this for addresses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424bc0d",
   "metadata": {},
   "source": [
    "#### Basics of Fuzzy Matching\n",
    "\n",
    "\"Fuzzy matching\" is called such because the matching it aims for is not exact or precise like a crystal clear image. It's kind of fuzzy like when you wear the wrong glasses prescription. In fuzzy matching, the word \"Bomegranate\" and \"Pomegranate\" would have a high match score even though they are different words, because they only differ by one character. \n",
    "\n",
    "There are many fuzzy matching approaches for strings, but the one we use is from the library `rapidfuzz` (https://pypi.org/project/rapidfuzz/). Below is an application of the library on our fruit motivated example.\n",
    "\n",
    "*(We haven't discussed exactly what's happening under the hood of the library, but feel free to check the library docs (https://rapidfuzz.github.io/RapidFuzz/Usage/fuzz.html#ratio) for details.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadf88c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.9090909090909"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "fuzz.ratio('Bomegranate', 'Pomegranate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a35ace",
   "metadata": {},
   "source": [
    "This example can be extended to one that better resembles the voter records problem. Say that a user inputs a string to a program. There might be misspellings in the input string, but we want to determine which fruit they *meant* to write. How can we use fuzzy matching to get the closest fruit? \n",
    "\n",
    "**One Approach:** \n",
    "1. Begin with a list of standard fruit\n",
    "2. Go through the list and compute the fuzzy match between the user input and an element in the list; Record the scores each time\n",
    "3. Output the list of fruits that have the highest match score to the user input. \n",
    "\n",
    "Here is a simple implementation of this procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d1049ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pomegranate', 90.9090909090909),\n",
       " ('Banana', 47.05882352941176),\n",
       " ('Orange', 47.05882352941176),\n",
       " ('Grapes', 35.29411764705882),\n",
       " ('Coconut', 33.333333333333336)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user input\n",
    "user_fruit = 'Bomegranate'\n",
    "\n",
    "# list of fruits\n",
    "fruit_list = ['Apple', 'Banana', 'Orange', 'Strawberry', 'Grapes', 'Mango', 'Pineapple', 'Watermelon', 'Blueberry', 'Cherry', 'Peach', 'Pear', 'Kiwi', 'Lemon', 'Lime', 'Raspberry', 'Blackberry', 'Pomegranate', 'Coconut', 'Papaya']\n",
    "\n",
    "# dictionary of scores\n",
    "score_dict = dict()\n",
    "for fruit_elem in fruit_list:\n",
    "    score_dict[fruit_elem] = fuzz.ratio(user_fruit, fruit_elem)\n",
    "\n",
    "# scores sorted by highest values\n",
    "list(dict(sorted(score_dict.items(), reverse=True, key=lambda item: item[1])).items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53351e60",
   "metadata": {},
   "source": [
    "We see that we correctly determined that \"Pomegranate\" has the highest score. Now, we want to apply the same procedure above to the ballot initiative problem The only difference is that we will use the OCR output (e.g., the Name and Address determined from the ballot) in place of `user_fruit` and we will use the list of registered voter names and addressed in place of `fruit_list`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15543c1",
   "metadata": {},
   "source": [
    " #### Fuzzy Matching and Voter Records\n",
    "\n",
    " Above, we applied \"fuzzy matching\" to a `user_input` of the name of a fruit and a `fruit_list` containing a list of fruit references. Next, we need to apply the same logic to check the output signature of the the OCR. The idea is the same. We have an input (or a collection of inputs) and we want to compare it with a list of possible inputs. \n",
    "\n",
    " For the ballot initiative problem, let's gather the list that is analogous to `fruit_list`: The list of registered voters. For simplicity we will focus only on the full names of these voters. \n",
    "\n",
    "First we import the voter records file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61fa2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# reading in election data; File is not stored locally in this repository\n",
    "voter_records_2023_df = pd.read_csv(f'{repo_root}/sample_data/fake_voter_records.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91c4a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Street_Number</th>\n",
       "      <th>Street_Name</th>\n",
       "      <th>Street_Type</th>\n",
       "      <th>Street_Dir_Suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Erica</td>\n",
       "      <td>Massey</td>\n",
       "      <td>6071</td>\n",
       "      <td>Martin Island</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terry</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>395</td>\n",
       "      <td>Kathryn Mall</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>30154</td>\n",
       "      <td>Tara Ports Apt. 314</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michele</td>\n",
       "      <td>Ballard</td>\n",
       "      <td>310</td>\n",
       "      <td>Landry Hills</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mary</td>\n",
       "      <td>Wiggins</td>\n",
       "      <td>26734</td>\n",
       "      <td>Susan Cliffs Suite 119</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First_Name Last_Name Street_Number             Street_Name Street_Type  \\\n",
       "0      Erica    Massey          6071           Martin Island               \n",
       "1      Terry   Osborne           395            Kathryn Mall               \n",
       "2      David    Holmes         30154     Tara Ports Apt. 314               \n",
       "3    Michele   Ballard           310            Landry Hills               \n",
       "4       Mary   Wiggins         26734  Susan Cliffs Suite 119               \n",
       "\n",
       "  Street_Dir_Suffix  \n",
       "0                    \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4                    "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying head of data; uncomment when want to see output\n",
    "voter_records_2023_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6428e",
   "metadata": {},
   "source": [
    "Next, we create a \"full name\" column in the dataframe, that we will use as our reference list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9262762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating full name column\n",
    "voter_records_2023_df['Full Name'] = voter_records_2023_df[\"First_Name\"] + ' ' + voter_records_2023_df['Last_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54584d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Erica Massey', 'Terry Osborne', 'David Holmes', 'Michele Ballard', 'Mary Wiggins', 'Audrey Smith', 'Willie Davis', 'Candace Jones', 'Patricia Hayes', 'Deborah Davies', 'Robert Boyd', 'Terry Meyer', 'Rachel Brown', 'Kathryn Brown', 'Sandra Stewart', 'Jacqueline Knox', 'Dr. Gina Burnett', 'Martin Collins', 'Colleen Stewart', 'Ryan Clark']\n"
     ]
    }
   ],
   "source": [
    "# converting column into a list and displaying first two entries\n",
    "full_name_list = list(voter_records_2023_df['Full Name'])\n",
    "\n",
    "# displaying first 20 entries\n",
    "print(full_name_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90451358",
   "metadata": {},
   "source": [
    "We now have our full list of registered voter names. Now when we have a name that we extract from the OCR, we can compare it with this list of names to find the close match. This is the first step in checking \"validating\" a signature. \n",
    "\n",
    "\n",
    "Take the first name that we extracted from the OCR \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb085930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marion Jones'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_data[0]['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88baa303",
   "metadata": {},
   "source": [
    "Now, we apply the same procedure as in the `user_fruit` and `fruit_list` example above to find the close matches to 'James Hatch' in the list of voter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd16aabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mario Jones', 95.65217391304348),\n",
       " ('Marvin Jones', 91.66666666666666),\n",
       " ('Madison Jones', 88.0),\n",
       " ('Aaron Jones', 86.95652173913044),\n",
       " ('Marco Jones', 86.95652173913044)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# signor name\n",
    "signor_name = resulting_data[0]['Name']\n",
    "\n",
    "# list of voters\n",
    "full_name_list\n",
    "\n",
    "# dictionary of scores\n",
    "voter_score_dict = dict()\n",
    "for voter_name in full_name_list:\n",
    "    voter_score_dict[voter_name] = fuzz.ratio(signor_name, voter_name)\n",
    "\n",
    "# scores sorted by highest values\n",
    "list(dict(sorted(voter_score_dict.items(), reverse=True, key=lambda item: item[1])).items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100a018",
   "metadata": {},
   "source": [
    "So we've found that there is indeed a \"James Hatch\" in the records of voters, and we completed the first part of the validation. The next part we would need to complete is checking that the address \"James Hatch\" wrote down matches that written in the voter registration records. We'll leave that as an extra task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e772597",
   "metadata": {},
   "source": [
    "Rapidfuzz contains an extract function which can perform this matching for one name against an entire iterable or collection of pandas dataframes at once.\n",
    "\n",
    "[Documentation for process.extract](https://rapidfuzz.github.io/RapidFuzz/Usage/process.html#extract)\n",
    "\n",
    "For ease of reference later, we can write this full process as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1997e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_fuzzy_match_slim(query_name, names_list):\n",
    "    # using ratio.fuzz as the scorer will return a score in standard % confidence, rather than default Levenshtein distance\n",
    "    # default_process removes whitespace, lowers all letters, removes any non-alphanumeric characters\n",
    "    list_of_match_tuples = process.extract(query=query_name, choices=names_list, scorer=fuzz.ratio, processor=utils.default_process, limit=5)\n",
    "    # this will produce a list of tuples whose values are as follows:\n",
    "    # (matched record: string, the record which the query matched*,\n",
    "    # score: float, % match confidence between the query and the matched record,\n",
    "    # index: when checked against an iterable i.e standard python list, this will be an index, when checked against panda dataframes, it will return a key)\n",
    "    return list_of_match_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b1d29eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mario Jones', 95.65217391304348, 80106),\n",
       " ('Marvin Jones', 91.66666666666666, 24287),\n",
       " ('Madison Jones', 88.0, 3636),\n",
       " ('Aaron Jones', 86.95652173913044, 2002),\n",
       " ('Marco Jones', 86.95652173913044, 36862)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding elmements in election database that are similar to a given string\n",
    "list_of_match_tuples = score_fuzzy_match_slim(resulting_data[0]['Name'], full_name_list)\n",
    "# returns a list of tuples in the format (matched_name, score, index), with percentage score truncated for readability\n",
    "list_of_match_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eea80a",
   "metadata": {},
   "source": [
    "## Full (Mini) Pipeline\n",
    "\n",
    "Now, that we have worked through the two pieces of starting the diagram, we can put the pieces together in a mini-pipeline\n",
    "\n",
    "<img src=\"ballot_initiative_flow.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "The process of the pipeline\n",
    "1. An image of a page of signed ballots comes in\n",
    "2. Perform GPT-based OCR to extract the names from page\n",
    "3. Compare each name in the extraction to voter record names\n",
    "4. Output the closest matches for the names (preferably in a table format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "037e3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full (mini) pipeline\n",
    "\n",
    "##############\n",
    "# BALLOT OCR #\n",
    "##############\n",
    "\n",
    "# defining single image path\n",
    "ballot_image = 'page-0.jpg'\n",
    "\n",
    "# ocr processing of image\n",
    "ocr_data = extract_signature_info(f\"{repo_root}/sample_data/{ballot_image}\")\n",
    "\n",
    "#######################\n",
    "# VALIDATION/MATCHING #\n",
    "#######################\n",
    "\n",
    "# empty list of voter signature data\n",
    "match_data = list()\n",
    "\n",
    "# cycling through processed data\n",
    "for elem in ocr_data:\n",
    "\n",
    "    # temporary dictionary of results\n",
    "    tmp_dict = dict()\n",
    "\n",
    "    # name determined from OCR\n",
    "    tmp_dict['OCR NAME'] = elem['Name']\n",
    "\n",
    "    # closest matched name, index and score of closest match name in records\n",
    "    name, score, index = score_fuzzy_match_slim(elem['Name'], full_name_list)[0]\n",
    "\n",
    "    # matched voter name\n",
    "    tmp_dict['MATCHED VOTER NAME'] = name\n",
    "\n",
    "    # match score\n",
    "    tmp_dict['MATCH_SCORE'] = score\n",
    "\n",
    "    # appending data to dictionary\n",
    "    match_data.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac4b65fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OCR NAME</th>\n",
       "      <th>MATCHED VOTER NAME</th>\n",
       "      <th>MATCH_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marion Jones</td>\n",
       "      <td>Mario Jones</td>\n",
       "      <td>95.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Smith</td>\n",
       "      <td>James Smith</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah Williams</td>\n",
       "      <td>Sarah Williams</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Johnson</td>\n",
       "      <td>Michael Johnson</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily Brown</td>\n",
       "      <td>Emily Brown</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          OCR NAME MATCHED VOTER NAME  MATCH_SCORE\n",
       "0     Marion Jones        Mario Jones    95.652174\n",
       "1      James Smith        James Smith   100.000000\n",
       "2   Sarah Williams     Sarah Williams   100.000000\n",
       "3  Michael Johnson    Michael Johnson   100.000000\n",
       "4      Emily Brown        Emily Brown   100.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying data and matches\n",
    "pd.DataFrame(match_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df0630",
   "metadata": {},
   "source": [
    "## Post-Onboarding Work\n",
    "\n",
    "That's the end of the onboarding notebook. If you worked through this, you now know the basic functions that run in the background of the application.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
